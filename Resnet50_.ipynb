{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0+cu111\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from torch.utils.data import random_split\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 및 라벨 파일 경로 설정\n",
    "data_folder = 'C:/Users/A/Desktop/224_Data'\n",
    "train_data_folder = data_folder + '/Train'\n",
    "test_data_folder = data_folder + '/Test'\n",
    "train_label_file = train_data_folder + '/train_labels.txt'\n",
    "test_label_file = test_data_folder + '/test_labels.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate for normalize(mean,std)\n",
    "def load_and_combine_data(train_data_folder):\n",
    "    file_paths = [os.path.join(train_data_folder, f) for f in os.listdir(train_data_folder) if f.endswith('9.txt')]\n",
    "    all_data = []\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        #Loading arrary data from each txt file\n",
    "        data = np.loadtxt(file_path)\n",
    "        all_data.append(data)\n",
    "\n",
    "    #combine all data to one file\n",
    "    combined_data = np.concatenate(all_data, axis=0)\n",
    "    return combined_data\n",
    "\n",
    "def calculate_statistics(data):\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    return mean, std\n",
    "\n",
    "combined_data = load_and_combine_data(train_data_folder)\n",
    "matrix_mean, matrix_std = calculate_statistics(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.019175920669329275 0.09508734685529101\n"
     ]
    }
   ],
   "source": [
    "#check the mean and std \n",
    "print(matrix_mean,matrix_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_folder, label_file, mean, std, label_mean=0, label_std=1):\n",
    "        self.data_folder = data_folder\n",
    "        self.parameters = self.read_parameters(label_file)  # 라벨 파일 경로를 인자로 받음\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "        self.data_numbers = list(self.parameters.keys())\n",
    "        all_params = np.array(list(self.parameters.values()))\n",
    "        self.label_min = np.min(all_params, axis=0)\n",
    "        self.label_max = np.max(all_params, axis=0)\n",
    "\n",
    "    def read_parameters(self, file_path):\n",
    "        parameters = {}\n",
    "        with open(file_path, 'r') as file:\n",
    "            for index, line in enumerate(file):\n",
    "                if index == 0:  # 첫 번째 줄(헤더) 건너뛰기\n",
    "                    continue\n",
    "                parts = line.strip().split(',')\n",
    "                data_number = parts[0]\n",
    "                params = np.array(parts[1:4], dtype=np.float32)\n",
    "                parameters[data_number] = params\n",
    "        return parameters\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_numbers)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_number = self.data_numbers[idx]\n",
    "        matrix_path = os.path.join(self.data_folder, f'{data_number}.txt')\n",
    "        matrix = np.loadtxt(matrix_path)  # Load matrix from a txt file\n",
    "        matrix = torch.from_numpy(matrix).float().unsqueeze(0)  # 2D -> 3D tensor\n",
    "        matrix = self.transform(matrix)\n",
    "        params = self.parameters[data_number]\n",
    "        \n",
    "        # label normalize\n",
    "        params = (params - self.label_min) / (self.label_max - self.label_min)\n",
    "        \n",
    "        return matrix, torch.from_numpy(params).float()\n",
    "\n",
    "# 훈련 및 테스트 데이터셋 생성\n",
    "train_dataset = CustomDataset(data_folder=train_data_folder, label_file=train_label_file, mean=0, std=1)\n",
    "test_dataset = CustomDataset(data_folder=test_data_folder, label_file=test_label_file, mean=0, std=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(train_dataset[0])\\nprint(test_dataset[0])'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the custom_dataset\n",
    "#print(train_dataset[0])\n",
    "#print(test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resnet50\n",
    "def resnet50(pretrained=False, progress=True, **kwargs):\n",
    "    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _resnet(resnet50, Bottleneck, layers, pretrained, progress, **kwargs):\n",
    "    r\"\"\"\n",
    "    - pretrained: pretrained된 모델 가중치를 불러오기 (saved by caffe)\n",
    "    - arch: ResNet모델 이름\n",
    "    - block: 어떤 block 형태 사용할지 (\"Basic or Bottleneck\")\n",
    "    - layers: 해당 block이 몇번 사용되는지를 list형태로 넘겨주는 부분\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, layers, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[resnet50], progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolution layer\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    r\"\"\"\n",
    "    3x3 convolution with padding\n",
    "    - in_planes: in_channels\n",
    "    - out_channels: out_channels\n",
    "    - bias=False: BatchNorm에 bias가 포함되어 있으므로, conv2d는 bias=False로 설정.\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bottleneck architecture\n",
    "class Bottleneck(nn.Module):\n",
    "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
    "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
    "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
    "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
    "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
    "\n",
    "    expansion = 4 # 블록 내에서 차원을 증가시키는 3번째 conv layer에서의 확장계수\n",
    "    \n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        # ResNext나 WideResNet의 경우 사용\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        \n",
    "        # Bottleneck Block의 구조\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation) # conv2에서 downsample\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        # 1x1 convolution layer\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        # 3x3 convolution layer\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        # 1x1 convolution layer\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        # skip connection\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "        # default values\n",
    "        self.inplanes = 64 # input feature map\n",
    "        self.dilation = 1\n",
    "        # stride를 dilation으로 대체할지 선택\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        \n",
    "        r\"\"\"\n",
    "        - 처음 입력에 적용되는 self.conv1과 self.bn1, self.relu는 모든 ResNet에서 동일 \n",
    "        - 3: 입력으로 RGB 이미지를 사용하기 때문에 convolution layer에 들어오는 input의 channel 수는 3 => matrix 사용할거라 1로 변경\n",
    "        \"\"\"\n",
    "        self.conv1 = nn.Conv2d(1, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        r\"\"\"\n",
    "        - 아래부터 block 형태와 갯수가 ResNet층마다 변화\n",
    "        - self.layer1 ~ 4: 필터의 개수는 각 block들을 거치면서 증가(64->128->256->512)\n",
    "        - self.avgpool: 모든 block을 거친 후에는 Adaptive AvgPool2d를 적용하여 (n, 512, 1, 1)의 텐서로\n",
    "        - self.fc: 이후 fc layer를 연결\n",
    "        \"\"\"\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, # 여기서부터 downsampling적용\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        r\"\"\"\n",
    "        convolution layer 생성 함수\n",
    "        - block: block종류 지정\n",
    "        - planes: feature map size (input shape)\n",
    "        - blocks: layers[0]와 같이, 해당 블록이 몇개 생성돼야하는지, 블록의 갯수 (layer 반복해서 쌓는 개수)\n",
    "        - stride와 dilate은 고정\n",
    "        \"\"\"\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        \n",
    "        # the number of filters is doubled: self.inplanes와 planes 사이즈를 맞춰주기 위한 projection shortcut\n",
    "        # the feature map size is halved: stride=2로 downsampling\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        # 블록 내 시작 layer, downsampling 필요\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion # inplanes 업데이트\n",
    "        # 동일 블록 반복\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_size = 3\n",
    "model_instance = resnet50(pretrained=False)\n",
    "model_instance.fc = nn.Linear(model_instance.fc.in_features, label_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model_instance.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5) #scheduler\n",
    "device = torch.device(\"cuda:0\")\n",
    "#model_instance.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchsummary import summary\n",
    "#summary(model_instance, (1, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.5537939427068105\n",
      "Epoch 2/100, Loss: 0.04911808724943045\n",
      "Epoch 3/100, Loss: 0.04823599212072991\n",
      "Epoch 4/100, Loss: 0.04062684660626424\n",
      "Epoch 5/100, Loss: 0.04382334191452812\n",
      "Epoch 6/100, Loss: 0.04381003296254454\n",
      "Epoch 7/100, Loss: 0.04162929745743404\n",
      "Epoch 8/100, Loss: 0.04439867635232371\n",
      "Epoch 9/100, Loss: 0.037566389787841485\n",
      "Epoch 10/100, Loss: 0.03776764577707729\n",
      "Epoch 11/100, Loss: 0.03918343565955355\n",
      "Epoch 12/100, Loss: 0.04280760728225515\n",
      "Epoch 13/100, Loss: 0.03778570613546951\n",
      "Epoch 14/100, Loss: 0.03930299371682309\n",
      "Epoch 15/100, Loss: 0.034213671913823566\n",
      "Epoch 16/100, Loss: 0.030945876512575795\n",
      "Epoch 17/100, Loss: 0.036378773432728405\n",
      "Epoch 18/100, Loss: 0.033867485317829495\n",
      "Epoch 19/100, Loss: 0.032913900257365125\n",
      "Epoch 20/100, Loss: 0.03420038526324001\n",
      "Epoch 21/100, Loss: 0.0327952809732508\n",
      "Epoch 22/100, Loss: 0.03171307115337333\n",
      "Epoch 23/100, Loss: 0.030109331364164483\n",
      "Epoch 24/100, Loss: 0.02980075711132707\n",
      "Epoch 25/100, Loss: 0.0344154170236072\n",
      "Epoch 26/100, Loss: 0.02575057835595028\n",
      "Epoch 27/100, Loss: 0.02758339072602826\n",
      "Epoch 28/100, Loss: 0.030611401524495433\n",
      "Epoch 29/100, Loss: 0.02771503573937996\n",
      "Epoch 30/100, Loss: 0.026410434948834213\n",
      "Epoch 31/100, Loss: 0.02274357119726168\n",
      "Epoch 32/100, Loss: 0.028387114002897933\n",
      "Epoch 33/100, Loss: 0.02230663436490136\n",
      "Epoch 34/100, Loss: 0.023891782262236684\n",
      "Epoch 35/100, Loss: 0.02385227842810186\n",
      "Epoch 36/100, Loss: 0.01920144753278913\n",
      "Epoch 37/100, Loss: 0.02575335747285469\n",
      "Epoch 38/100, Loss: 0.026041486451553332\n",
      "Epoch 39/100, Loss: 0.02335677029111901\n",
      "Epoch 40/100, Loss: 0.019267308399886697\n",
      "Epoch 41/100, Loss: 0.019565567751792638\n",
      "Epoch 42/100, Loss: 0.02030260133481509\n",
      "Epoch 43/100, Loss: 0.02288138838736592\n",
      "Epoch 44/100, Loss: 0.01781221046238332\n",
      "Epoch 45/100, Loss: 0.01992468013604348\n",
      "Epoch 46/100, Loss: 0.017132076887866936\n",
      "Epoch 47/100, Loss: 0.018184442652037013\n",
      "Epoch 48/100, Loss: 0.02143210731446743\n",
      "Epoch 49/100, Loss: 0.022661420214619185\n",
      "Epoch 50/100, Loss: 0.019963090156985296\n",
      "Epoch 51/100, Loss: 0.01683618820498924\n",
      "Epoch 52/100, Loss: 0.01732728782588163\n",
      "Epoch 53/100, Loss: 0.01830859693723756\n",
      "Epoch 54/100, Loss: 0.019189347538190918\n",
      "Epoch 55/100, Loss: 0.018264559349296865\n",
      "Epoch 56/100, Loss: 0.014483275332462948\n",
      "Epoch 57/100, Loss: 0.016425183697326762\n",
      "Epoch 58/100, Loss: 0.015783926811874717\n",
      "Epoch 59/100, Loss: 0.01953590560603786\n",
      "Epoch 60/100, Loss: 0.01855701668741735\n",
      "Epoch 61/100, Loss: 0.01557088499838436\n",
      "Epoch 62/100, Loss: 0.012971134340340222\n",
      "Epoch 63/100, Loss: 0.01637411120070799\n",
      "Epoch 64/100, Loss: 0.01471584859127934\n",
      "Epoch 65/100, Loss: 0.01551510170857246\n",
      "Epoch 66/100, Loss: 0.013518333447644033\n",
      "Epoch 67/100, Loss: 0.014238079745523833\n",
      "Epoch 68/100, Loss: 0.01607369919735435\n",
      "Epoch 69/100, Loss: 0.015167812904896768\n",
      "Epoch 70/100, Loss: 0.016370078397763742\n",
      "Epoch 71/100, Loss: 0.01203972174207101\n",
      "Epoch 72/100, Loss: 0.012111552412042747\n",
      "Epoch 73/100, Loss: 0.013207686397976972\n",
      "Epoch 74/100, Loss: 0.013455066339087647\n",
      "Epoch 75/100, Loss: 0.01276107199137678\n",
      "Epoch 76/100, Loss: 0.013008486366251836\n",
      "Epoch 77/100, Loss: 0.012658293220541766\n",
      "Epoch 78/100, Loss: 0.012915556721792027\n",
      "Epoch 79/100, Loss: 0.01503040233777987\n",
      "Epoch 80/100, Loss: 0.012377724945041779\n",
      "Epoch 81/100, Loss: 0.012417269417563\n",
      "Epoch 82/100, Loss: 0.016947481655389875\n",
      "Epoch 83/100, Loss: 0.013559835270751972\n",
      "Epoch 84/100, Loss: 0.012571796044908665\n",
      "Epoch 85/100, Loss: 0.013126626786952084\n",
      "Epoch 86/100, Loss: 0.023718476018591506\n",
      "Epoch 87/100, Loss: 0.017474133949223404\n",
      "Epoch 88/100, Loss: 0.014915926180578567\n",
      "Epoch 89/100, Loss: 0.01526148963367214\n",
      "Epoch 90/100, Loss: 0.014487636162320504\n",
      "Epoch 91/100, Loss: 0.014332780652251598\n",
      "Epoch 92/100, Loss: 0.011607905434494888\n",
      "Epoch 93/100, Loss: 0.015562386000277224\n",
      "Epoch 94/100, Loss: 0.014650627429521567\n",
      "Epoch 95/100, Loss: 0.012186450128619736\n",
      "Epoch 96/100, Loss: 0.014597525643939907\n",
      "Epoch 97/100, Loss: 0.012079023630232425\n",
      "Epoch 98/100, Loss: 0.012791920075746806\n",
      "Epoch 99/100, Loss: 0.0113059775903821\n",
      "Epoch 100/100, Loss: 0.008994979595111028\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100 #batch=64\n",
    "losses = [] \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_instance.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_instance(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    epoch_loss = running_loss / len(train_loader)  #epoch당 평균 loss 계산\n",
    "    losses.append(epoch_loss)  #add list\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss}')\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score:  0.32564083504397656\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# CUDA에서 CPU로 텐서 이동\n",
    "outputs_cpu = outputs.cpu()\n",
    "labels_cpu = labels.cpu()\n",
    "\n",
    "# 텐서를 NumPy 배열로 변환\n",
    "outputs_np = outputs_cpu.detach().numpy()\n",
    "labels_np = labels_cpu.detach().numpy()\n",
    "\n",
    "# R^2 점수 계산\n",
    "print(\"R2 score: \", r2_score(labels_np, outputs_np))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.013098804280161858\n",
      "Test MSE: 0.009509814903140068\n",
      "Test MSE: 0.009694532491266727\n",
      "Test MSE: 0.009295688476413488\n",
      "Test MSE: 0.010344114154577255\n",
      "Test MSE: 0.012729196498791376\n",
      "Test MSE: 0.017276337104184285\n",
      "Test MSE: 0.025523043237626553\n",
      "Test MSE: 0.03567341135607825\n",
      "Test MSE: 0.03559821502401911\n",
      "Whole Test MSE: 0.03559821502401911\n"
     ]
    }
   ],
   "source": [
    "model_instance.eval()  # 평가 모드로 전환\n",
    "test_loss = 0.0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():  # 기울기 계산 비활성화\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model_instance(inputs)\n",
    "\n",
    "        # MSE 손실 계산\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * inputs.size(0)  # 배치에 대한 손실을 누적하고, 샘플 수로 가중치를 줌\n",
    "        total_samples += inputs.size(0)\n",
    "        avg_test_mse = test_loss / total_samples\n",
    "        print(f'Test MSE: {avg_test_mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "custom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
