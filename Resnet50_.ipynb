{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from torch.utils.data import random_split\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'C:/Users/A/Desktop/Training_data_128/customData_anse'\n",
    "parameters_file = data_folder + '/0_Data.txt'\n",
    "\n",
    "#calculate for normalize(mean,std)\n",
    "def load_and_combine_data(data_folder):\n",
    "    file_paths = [os.path.join(data_folder, f) for f in os.listdir(data_folder) if f.endswith('9.txt')]\n",
    "    all_data = []\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        #Loading arrary data from each txt file\n",
    "        data = np.loadtxt(file_path)\n",
    "        all_data.append(data)\n",
    "\n",
    "    #combine all data to one file\n",
    "    combined_data = np.concatenate(all_data, axis=0)\n",
    "    return combined_data\n",
    "\n",
    "def calculate_statistics(data):\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    return mean, std\n",
    "\n",
    "combined_data = load_and_combine_data(data_folder)\n",
    "mean, std = calculate_statistics(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.029182019126922178 0.11373121119680919\n"
     ]
    }
   ],
   "source": [
    "#check the mean and std \n",
    "print(mean,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_folder, parameters_file, mean, std):\n",
    "        self.data_folder = data_folder\n",
    "        self.parameters = self.read_parameters(parameters_file)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "        self.data_numbers = [data_num for data_num in self.parameters.keys() if data_num.endswith('9')]\n",
    "\n",
    "#Read '0_Data.txt'\n",
    "    def read_parameters(self, file_path):\n",
    "        parameters = {}\n",
    "        with open(file_path, 'r') as file:\n",
    "            for index, line in enumerate(file):\n",
    "                if index == 0:  # Skip 1st row\n",
    "                    continue\n",
    "                parts = line.strip().split(',')\n",
    "                data_number = parts[0]\n",
    "                params = np.array(parts[1:4], dtype=np.float32)\n",
    "                parameters[data_number] = params\n",
    "        return parameters\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_numbers)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_number = self.data_numbers[idx]\n",
    "        matrix_path = os.path.join(self.data_folder, f'{data_number}.txt')\n",
    "        matrix = np.loadtxt(matrix_path)  # Load matrix from a txt file\n",
    "        matrix = torch.from_numpy(matrix).float().unsqueeze(0)  # 2D -> 3D tensor\n",
    "        matrix = self.transform(matrix)\n",
    "        params = self.parameters[data_number]\n",
    "        return matrix, params\n",
    "\n",
    "custom_dataset = CustomDataset(data_folder=data_folder, parameters_file=parameters_file, mean=mean, std=std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-3.5984, -3.5983, -3.5956,  ...,  0.2761,  0.2767,  0.2772],\n",
      "         [-3.5987, -3.5974, -3.5946,  ...,  0.2762,  0.2767,  0.2772],\n",
      "         [-3.5958, -3.5948, -3.5920,  ...,  0.2762,  0.2767,  0.2773],\n",
      "         ...,\n",
      "         [ 0.2762,  0.2762,  0.2763,  ...,  0.2789,  0.2787,  0.2786],\n",
      "         [ 0.2767,  0.2767,  0.2768,  ...,  0.2787,  0.2786,  0.2784],\n",
      "         [ 0.2772,  0.2772,  0.2773,  ...,  0.2786,  0.2784,  0.2782]]]), array([0.0e+00, 5.5e-01, 1.5e+03], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "#check the custom_dataset\n",
    "print(custom_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(custom_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resnet50\n",
    "def resnet50(pretrained=False, progress=True, **kwargs):\n",
    "    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _resnet(resnet50, Bottleneck, layers, pretrained, progress, **kwargs):\n",
    "    r\"\"\"\n",
    "    - pretrained: pretrained된 모델 가중치를 불러오기 (saved by caffe)\n",
    "    - arch: ResNet모델 이름\n",
    "    - block: 어떤 block 형태 사용할지 (\"Basic or Bottleneck\")\n",
    "    - layers: 해당 block이 몇번 사용되는지를 list형태로 넘겨주는 부분\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, layers, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[resnet50], progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolution layer\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    r\"\"\"\n",
    "    3x3 convolution with padding\n",
    "    - in_planes: in_channels\n",
    "    - out_channels: out_channels\n",
    "    - bias=False: BatchNorm에 bias가 포함되어 있으므로, conv2d는 bias=False로 설정.\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bottleneck architecture\n",
    "class Bottleneck(nn.Module):\n",
    "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
    "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
    "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
    "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
    "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
    "\n",
    "    expansion = 4 # 블록 내에서 차원을 증가시키는 3번째 conv layer에서의 확장계수\n",
    "    \n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        # ResNext나 WideResNet의 경우 사용\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        \n",
    "        # Bottleneck Block의 구조\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation) # conv2에서 downsample\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        # 1x1 convolution layer\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        # 3x3 convolution layer\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        # 1x1 convolution layer\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        # skip connection\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "        # default values\n",
    "        self.inplanes = 64 # input feature map\n",
    "        self.dilation = 1\n",
    "        # stride를 dilation으로 대체할지 선택\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        \n",
    "        r\"\"\"\n",
    "        - 처음 입력에 적용되는 self.conv1과 self.bn1, self.relu는 모든 ResNet에서 동일 \n",
    "        - 3: 입력으로 RGB 이미지를 사용하기 때문에 convolution layer에 들어오는 input의 channel 수는 3 => matrix 사용할거라 1로 변경\n",
    "        \"\"\"\n",
    "        self.conv1 = nn.Conv2d(1, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        r\"\"\"\n",
    "        - 아래부터 block 형태와 갯수가 ResNet층마다 변화\n",
    "        - self.layer1 ~ 4: 필터의 개수는 각 block들을 거치면서 증가(64->128->256->512)\n",
    "        - self.avgpool: 모든 block을 거친 후에는 Adaptive AvgPool2d를 적용하여 (n, 512, 1, 1)의 텐서로\n",
    "        - self.fc: 이후 fc layer를 연결\n",
    "        \"\"\"\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, # 여기서부터 downsampling적용\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        r\"\"\"\n",
    "        convolution layer 생성 함수\n",
    "        - block: block종류 지정\n",
    "        - planes: feature map size (input shape)\n",
    "        - blocks: layers[0]와 같이, 해당 블록이 몇개 생성돼야하는지, 블록의 갯수 (layer 반복해서 쌓는 개수)\n",
    "        - stride와 dilate은 고정\n",
    "        \"\"\"\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        \n",
    "        # the number of filters is doubled: self.inplanes와 planes 사이즈를 맞춰주기 위한 projection shortcut\n",
    "        # the feature map size is halved: stride=2로 downsampling\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        # 블록 내 시작 layer, downsampling 필요\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion # inplanes 업데이트\n",
    "        # 동일 블록 반복\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_size = 3\n",
    "model_instance = resnet50(pretrained=False)\n",
    "model_instance.fc = nn.Linear(model_instance.fc.in_features, label_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model_instance.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5) #scheduler\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_instance.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           3,136\n",
      "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
      "              ReLU-3           [-1, 64, 64, 64]               0\n",
      "         MaxPool2d-4           [-1, 64, 32, 32]               0\n",
      "            Conv2d-5           [-1, 64, 32, 32]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "              ReLU-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "             ReLU-10           [-1, 64, 32, 32]               0\n",
      "           Conv2d-11          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 32, 32]             512\n",
      "           Conv2d-13          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 32, 32]             512\n",
      "             ReLU-15          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-16          [-1, 256, 32, 32]               0\n",
      "           Conv2d-17           [-1, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 32, 32]             128\n",
      "             ReLU-19           [-1, 64, 32, 32]               0\n",
      "           Conv2d-20           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 32, 32]             128\n",
      "             ReLU-22           [-1, 64, 32, 32]               0\n",
      "           Conv2d-23          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 32, 32]             512\n",
      "             ReLU-25          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-26          [-1, 256, 32, 32]               0\n",
      "           Conv2d-27           [-1, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 32, 32]             128\n",
      "             ReLU-29           [-1, 64, 32, 32]               0\n",
      "           Conv2d-30           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 32, 32]             128\n",
      "             ReLU-32           [-1, 64, 32, 32]               0\n",
      "           Conv2d-33          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 32, 32]             512\n",
      "             ReLU-35          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-36          [-1, 256, 32, 32]               0\n",
      "           Conv2d-37          [-1, 128, 32, 32]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 32, 32]             256\n",
      "             ReLU-39          [-1, 128, 32, 32]               0\n",
      "           Conv2d-40          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 16, 16]             256\n",
      "             ReLU-42          [-1, 128, 16, 16]               0\n",
      "           Conv2d-43          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 16, 16]           1,024\n",
      "           Conv2d-45          [-1, 512, 16, 16]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-47          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-48          [-1, 512, 16, 16]               0\n",
      "           Conv2d-49          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 16, 16]             256\n",
      "             ReLU-51          [-1, 128, 16, 16]               0\n",
      "           Conv2d-52          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 16, 16]             256\n",
      "             ReLU-54          [-1, 128, 16, 16]               0\n",
      "           Conv2d-55          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-57          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-58          [-1, 512, 16, 16]               0\n",
      "           Conv2d-59          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 16, 16]             256\n",
      "             ReLU-61          [-1, 128, 16, 16]               0\n",
      "           Conv2d-62          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 16, 16]             256\n",
      "             ReLU-64          [-1, 128, 16, 16]               0\n",
      "           Conv2d-65          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-67          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-68          [-1, 512, 16, 16]               0\n",
      "           Conv2d-69          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 16, 16]             256\n",
      "             ReLU-71          [-1, 128, 16, 16]               0\n",
      "           Conv2d-72          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 16, 16]             256\n",
      "             ReLU-74          [-1, 128, 16, 16]               0\n",
      "           Conv2d-75          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-77          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-78          [-1, 512, 16, 16]               0\n",
      "           Conv2d-79          [-1, 256, 16, 16]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 16, 16]             512\n",
      "             ReLU-81          [-1, 256, 16, 16]               0\n",
      "           Conv2d-82            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 8, 8]             512\n",
      "             ReLU-84            [-1, 256, 8, 8]               0\n",
      "           Conv2d-85           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-86           [-1, 1024, 8, 8]           2,048\n",
      "           Conv2d-87           [-1, 1024, 8, 8]         524,288\n",
      "      BatchNorm2d-88           [-1, 1024, 8, 8]           2,048\n",
      "             ReLU-89           [-1, 1024, 8, 8]               0\n",
      "       Bottleneck-90           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-91            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-92            [-1, 256, 8, 8]             512\n",
      "             ReLU-93            [-1, 256, 8, 8]               0\n",
      "           Conv2d-94            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-95            [-1, 256, 8, 8]             512\n",
      "             ReLU-96            [-1, 256, 8, 8]               0\n",
      "           Conv2d-97           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-98           [-1, 1024, 8, 8]           2,048\n",
      "             ReLU-99           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-100           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-101            [-1, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-102            [-1, 256, 8, 8]             512\n",
      "            ReLU-103            [-1, 256, 8, 8]               0\n",
      "          Conv2d-104            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-105            [-1, 256, 8, 8]             512\n",
      "            ReLU-106            [-1, 256, 8, 8]               0\n",
      "          Conv2d-107           [-1, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-108           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-109           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-110           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-111            [-1, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-112            [-1, 256, 8, 8]             512\n",
      "            ReLU-113            [-1, 256, 8, 8]               0\n",
      "          Conv2d-114            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-115            [-1, 256, 8, 8]             512\n",
      "            ReLU-116            [-1, 256, 8, 8]               0\n",
      "          Conv2d-117           [-1, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-118           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-119           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-120           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-121            [-1, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-122            [-1, 256, 8, 8]             512\n",
      "            ReLU-123            [-1, 256, 8, 8]               0\n",
      "          Conv2d-124            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-125            [-1, 256, 8, 8]             512\n",
      "            ReLU-126            [-1, 256, 8, 8]               0\n",
      "          Conv2d-127           [-1, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-128           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-129           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-130           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-131            [-1, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-132            [-1, 256, 8, 8]             512\n",
      "            ReLU-133            [-1, 256, 8, 8]               0\n",
      "          Conv2d-134            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-135            [-1, 256, 8, 8]             512\n",
      "            ReLU-136            [-1, 256, 8, 8]               0\n",
      "          Conv2d-137           [-1, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-138           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-139           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-140           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-141            [-1, 512, 8, 8]         524,288\n",
      "     BatchNorm2d-142            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-143            [-1, 512, 8, 8]               0\n",
      "          Conv2d-144            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-146            [-1, 512, 4, 4]               0\n",
      "          Conv2d-147           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 4, 4]           4,096\n",
      "          Conv2d-149           [-1, 2048, 4, 4]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 4, 4]           4,096\n",
      "            ReLU-151           [-1, 2048, 4, 4]               0\n",
      "      Bottleneck-152           [-1, 2048, 4, 4]               0\n",
      "          Conv2d-153            [-1, 512, 4, 4]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-155            [-1, 512, 4, 4]               0\n",
      "          Conv2d-156            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-158            [-1, 512, 4, 4]               0\n",
      "          Conv2d-159           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 4, 4]           4,096\n",
      "            ReLU-161           [-1, 2048, 4, 4]               0\n",
      "      Bottleneck-162           [-1, 2048, 4, 4]               0\n",
      "          Conv2d-163            [-1, 512, 4, 4]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-165            [-1, 512, 4, 4]               0\n",
      "          Conv2d-166            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-168            [-1, 512, 4, 4]               0\n",
      "          Conv2d-169           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 4, 4]           4,096\n",
      "            ReLU-171           [-1, 2048, 4, 4]               0\n",
      "      Bottleneck-172           [-1, 2048, 4, 4]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                    [-1, 3]           6,147\n",
      "================================================================\n",
      "Total params: 23,507,907\n",
      "Trainable params: 23,507,907\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 93.58\n",
      "Params size (MB): 89.68\n",
      "Estimated Total Size (MB): 183.32\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model_instance, (1, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.2185e-01,  5.8885e-02,  1.3040e+03],\n",
      "        [-4.3964e-01, -1.5880e-01,  8.6542e+02],\n",
      "        [-7.3193e-01,  3.2876e-03,  1.3179e+03],\n",
      "        [-4.6641e-01, -6.5925e-01,  9.4064e+02],\n",
      "        [-8.2138e-01, -1.8040e-01,  1.4700e+03],\n",
      "        [-7.0285e-01,  2.0237e-02,  1.2366e+03],\n",
      "        [-4.4524e-01, -2.1942e-01,  8.3990e+02],\n",
      "        [-7.0510e-01,  2.2220e-02,  1.2388e+03],\n",
      "        [-6.5323e-01,  1.6875e-02,  1.1561e+03],\n",
      "        [-8.4940e-01, -2.2732e-01,  1.5155e+03],\n",
      "        [-8.4853e-01, -2.2522e-01,  1.5135e+03],\n",
      "        [-6.2543e-01,  5.6069e-02,  1.1259e+03],\n",
      "        [-7.1718e-01,  4.2187e-02,  1.3070e+03],\n",
      "        [-8.3330e-01, -1.8615e-01,  1.4822e+03],\n",
      "        [-6.2057e-01,  6.2921e-02,  1.1120e+03],\n",
      "        [-7.4995e-01, -3.4862e-02,  1.3457e+03],\n",
      "        [-5.9842e-01,  6.2783e-02,  1.1084e+03],\n",
      "        [-6.7190e-01, -1.0576e-02,  1.1052e+03],\n",
      "        [-6.8591e-01,  1.9358e-02,  1.2075e+03],\n",
      "        [-8.4580e-01, -2.1830e-01,  1.5070e+03],\n",
      "        [-5.5383e-01,  4.6901e-02,  1.0476e+03],\n",
      "        [-4.4518e-01, -7.5839e-01,  9.1309e+02],\n",
      "        [-7.1156e-01, -6.2649e-03,  1.2549e+03],\n",
      "        [-8.2326e-01, -1.7888e-01,  1.4676e+03],\n",
      "        [-6.8960e-01,  4.4838e-02,  1.2301e+03],\n",
      "        [-4.5166e-01, -4.2418e-01,  7.6622e+02],\n",
      "        [-7.7876e-01, -9.4838e-02,  1.3879e+03],\n",
      "        [-8.5362e-01, -2.3036e-01,  1.5200e+03],\n",
      "        [-7.7334e-01, -8.6170e-02,  1.3884e+03],\n",
      "        [-7.1313e-01, -4.6077e-03,  1.2740e+03],\n",
      "        [-6.8552e-01,  7.2558e-02,  1.2419e+03],\n",
      "        [-8.5159e-01, -2.3564e-01,  1.5257e+03]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-6.0968e-01,  8.5746e-02,  1.1376e+03],\n",
      "        [-5.8754e-01,  7.3777e-02,  1.0880e+03],\n",
      "        [-4.6314e-01, -1.0623e-01,  9.8744e+02],\n",
      "        [-4.3777e-01, -1.5730e-01,  8.2573e+02],\n",
      "        [-8.7476e-01, -2.0041e-01,  1.4819e+03],\n",
      "        [-8.7890e-01, -2.4128e-01,  1.5121e+03],\n",
      "        [-8.3998e-01, -1.3687e-01,  1.3834e+03],\n",
      "        [-8.9391e-01, -2.6983e-01,  1.5497e+03],\n",
      "        [-4.9281e-01, -4.8658e-01,  9.1183e+02],\n",
      "        [-6.3356e-01,  6.5242e-02,  1.1132e+03],\n",
      "        [-9.0392e-01, -2.8233e-01,  1.5650e+03],\n",
      "        [-8.7487e-01, -2.4045e-01,  1.5136e+03],\n",
      "        [-5.6200e-01,  5.5204e-02,  1.0239e+03],\n",
      "        [-8.4926e-01, -1.6405e-01,  1.4950e+03],\n",
      "        [-8.9613e-01, -2.7001e-01,  1.5555e+03],\n",
      "        [-4.6845e-01, -3.3632e-02,  9.6603e+02],\n",
      "        [-6.8318e-01,  3.2762e-02,  1.1920e+03],\n",
      "        [-8.8028e-01, -2.4801e-01,  1.5197e+03],\n",
      "        [-4.8122e-01, -3.0873e-01,  7.8679e+02],\n",
      "        [-7.5668e-01, -3.7814e-02,  1.3257e+03],\n",
      "        [-8.6899e-01, -2.2590e-01,  1.5130e+03],\n",
      "        [-8.2395e-01, -1.5919e-01,  1.4179e+03],\n",
      "        [-8.3337e-01, -1.7980e-01,  1.4429e+03],\n",
      "        [-8.8905e-01, -2.1553e-01,  1.4943e+03],\n",
      "        [-7.8705e-01, -8.3557e-02,  1.2952e+03],\n",
      "        [-7.4223e-01, -8.4164e-03,  1.3085e+03],\n",
      "        [-4.6140e-01, -3.4261e-01,  9.2817e+02],\n",
      "        [-7.2162e-01,  3.1537e-02,  1.2862e+03],\n",
      "        [-5.4348e-01,  6.4907e-02,  1.0531e+03],\n",
      "        [-6.2700e-01,  1.4156e-03,  1.0412e+03],\n",
      "        [-5.8641e-01,  6.9474e-02,  1.1014e+03],\n",
      "        [-4.8262e-01, -5.4055e-02,  9.9892e+02]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-8.7435e-01, -2.3238e-01,  1.5441e+03],\n",
      "        [-8.5656e-01, -1.7883e-01,  1.4807e+03],\n",
      "        [-4.7072e-01,  7.5272e-02,  9.9208e+02],\n",
      "        [-8.7889e-01, -1.8634e-01,  1.5097e+03],\n",
      "        [-8.3201e-01, -1.3828e-01,  1.4236e+03],\n",
      "        [-8.5225e-01, -2.1363e-01,  1.5155e+03],\n",
      "        [-4.5925e-01, -3.9977e-01,  7.7256e+02],\n",
      "        [-7.6068e-01, -5.2907e-02,  1.3493e+03],\n",
      "        [-8.6614e-01, -2.1588e-01,  1.5299e+03],\n",
      "        [-8.7475e-01, -2.3396e-01,  1.5454e+03],\n",
      "        [-4.7810e-01, -5.7038e-01,  9.9441e+02],\n",
      "        [-7.5181e-01,  1.8885e-02,  1.2720e+03],\n",
      "        [-7.7572e-01, -8.7692e-02,  1.3710e+03],\n",
      "        [-4.5167e-01, -2.2300e-01,  9.8592e+02],\n",
      "        [-6.2677e-01,  8.1399e-02,  1.1761e+03],\n",
      "        [-6.8393e-01,  6.2703e-02,  1.1277e+03],\n",
      "        [-5.8471e-01,  2.8721e-02,  9.6719e+02],\n",
      "        [-6.1146e-01,  4.9590e-02,  1.1382e+03],\n",
      "        [-4.9333e-01, -2.0852e-02,  9.5410e+02],\n",
      "        [-7.9378e-01, -1.2461e-01,  1.4163e+03],\n",
      "        [-5.2613e-01,  7.4155e-02,  9.7692e+02],\n",
      "        [-8.7509e-01, -2.3557e-01,  1.5467e+03],\n",
      "        [-8.8749e-01, -2.5206e-01,  1.5755e+03],\n",
      "        [-7.5297e-01, -6.1824e-02,  1.3382e+03],\n",
      "        [-6.8629e-01,  5.6158e-02,  1.2190e+03],\n",
      "        [-6.1024e-01,  9.9866e-02,  1.0999e+03],\n",
      "        [-6.9294e-01, -6.0279e-02,  1.2921e+03],\n",
      "        [-6.1065e-01,  2.7945e-02,  1.1348e+03],\n",
      "        [-4.4999e-01, -1.5662e-01,  8.3970e+02],\n",
      "        [-5.7313e-01,  5.4666e-02,  1.0708e+03],\n",
      "        [-4.9175e-01, -9.1987e-03,  9.5664e+02],\n",
      "        [-8.3340e-01, -1.7705e-01,  1.4768e+03]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-4.5449e-01, -5.1803e-01,  9.1469e+02],\n",
      "        [-8.3575e-01, -1.4407e-01,  1.4767e+03],\n",
      "        [-7.9838e-01, -8.9102e-02,  1.4153e+03],\n",
      "        [-4.5392e-01, -2.0384e-01,  8.3913e+02],\n",
      "        [-6.9779e-01,  4.0895e-02,  1.2247e+03],\n",
      "        [-4.6710e-01, -1.4466e-01,  8.5778e+02],\n",
      "        [-6.9347e-01,  5.6904e-02,  1.2405e+03],\n",
      "        [-8.6885e-01, -2.1324e-01,  1.5472e+03],\n",
      "        [-4.5477e-01, -2.3643e-01,  9.4082e+02],\n",
      "        [-8.8086e-01, -2.1985e-01,  1.5609e+03],\n",
      "        [-8.2984e-01, -1.3371e-01,  1.4658e+03],\n",
      "        [-5.9375e-01,  7.7987e-02,  1.0730e+03],\n",
      "        [-5.2347e-01, -1.9569e-01,  8.2924e+02],\n",
      "        [-5.3801e-01, -2.4064e-02,  9.4676e+02],\n",
      "        [-5.5556e-01,  9.7007e-02,  1.0224e+03],\n",
      "        [-7.8572e-01, -7.6602e-02,  1.3464e+03],\n",
      "        [-8.8067e-01, -2.1020e-01,  1.5543e+03],\n",
      "        [-6.5824e-01,  2.2091e-02,  1.1736e+03],\n",
      "        [-8.7158e-01, -2.1345e-01,  1.5486e+03],\n",
      "        [-5.2196e-01,  3.6693e-02,  9.9213e+02],\n",
      "        [-8.5757e-01, -1.7774e-01,  1.4992e+03],\n",
      "        [-8.1653e-01, -1.2227e-01,  1.4496e+03],\n",
      "        [-8.7129e-01, -2.0431e-01,  1.5424e+03],\n",
      "        [-6.8342e-01,  6.9852e-02,  1.2210e+03],\n",
      "        [-5.5646e-01,  1.0058e-01,  1.0534e+03],\n",
      "        [-4.6249e-01, -5.9695e-01,  9.1990e+02],\n",
      "        [-8.6265e-01, -2.0343e-01,  1.5357e+03],\n",
      "        [-7.6099e-01, -3.5037e-03,  1.3362e+03],\n",
      "        [-7.6530e-01, -4.9411e-02,  1.3748e+03],\n",
      "        [-7.3493e-01,  3.3760e-04,  1.2846e+03],\n",
      "        [-5.8472e-01,  6.2366e-02,  1.0596e+03],\n",
      "        [-8.0572e-01, -1.0300e-01,  1.3911e+03]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-5.3112e-01, -1.8899e-01,  8.3289e+02],\n",
      "        [-7.0327e-01, -7.2185e-02,  1.2514e+03],\n",
      "        [-9.1076e-01, -2.4972e-01,  1.5885e+03],\n",
      "        [-5.5090e-01, -2.6520e-02,  9.7998e+02],\n",
      "        [-4.6668e-01, -1.0516e-01,  9.6280e+02],\n",
      "        [-8.8170e-01, -1.9219e-01,  1.5035e+03],\n",
      "        [-8.8026e-01, -1.7195e-01,  1.4856e+03],\n",
      "        [-6.3508e-01,  2.5160e-02,  1.0375e+03],\n",
      "        [-4.5615e-01, -1.5247e-03,  9.8333e+02],\n",
      "        [-5.5349e-01,  6.7401e-02,  1.0054e+03],\n",
      "        [-7.3773e-01, -7.6076e-03,  1.3116e+03],\n",
      "        [-8.3785e-01, -1.7928e-01,  1.4884e+03],\n",
      "        [-6.1578e-01,  3.1672e-02,  1.1114e+03],\n",
      "        [-4.3721e-01, -4.4277e-01,  9.2279e+02],\n",
      "        [-5.8863e-01,  8.7030e-02,  1.0782e+03],\n",
      "        [-6.9884e-01,  6.5496e-03,  1.2141e+03],\n",
      "        [-5.3754e-01,  9.8373e-02,  1.0029e+03],\n",
      "        [-8.8293e-01, -2.2230e-01,  1.5444e+03],\n",
      "        [-9.0521e-01, -2.6578e-01,  1.5952e+03],\n",
      "        [-7.9264e-01, -1.0639e-01,  1.3946e+03],\n",
      "        [-8.8195e-01, -2.3824e-01,  1.5591e+03],\n",
      "        [-5.9893e-01, -1.2208e-02,  9.7293e+02],\n",
      "        [-8.9674e-01, -2.5718e-01,  1.5781e+03],\n",
      "        [-5.0160e-01,  3.6664e-02,  9.9794e+02],\n",
      "        [-8.9645e-01, -2.4598e-01,  1.5754e+03],\n",
      "        [-5.9444e-01, -1.1727e-02,  9.7259e+02],\n",
      "        [-7.4331e-01,  3.7690e-02,  1.2468e+03],\n",
      "        [-9.0780e-01, -2.6423e-01,  1.5969e+03],\n",
      "        [-6.8312e-01,  2.6165e-02,  1.2174e+03],\n",
      "        [-4.3931e-01, -2.5402e-01,  9.3782e+02],\n",
      "        [-5.6650e-01,  1.1827e-01,  1.0771e+03],\n",
      "        [-8.9804e-01, -2.3147e-01,  1.5616e+03]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-9.1521e-01, -3.0694e-01,  1.6081e+03],\n",
      "        [-9.1174e-01, -2.9385e-01,  1.5974e+03],\n",
      "        [-9.2704e-01, -2.9114e-01,  1.6116e+03],\n",
      "        [-7.2443e-01, -3.0626e-02,  1.2504e+03],\n",
      "        [-9.1486e-01, -2.8481e-01,  1.5952e+03],\n",
      "        [-8.9335e-01, -2.0826e-01,  1.4962e+03],\n",
      "        [-4.7946e-01, -4.1318e-01,  7.7505e+02],\n",
      "        [-7.6900e-01, -4.4793e-02,  1.3022e+03],\n",
      "        [-7.5693e-01, -2.8061e-02,  1.3161e+03],\n",
      "        [-4.8740e-01,  7.0981e-03,  9.5692e+02],\n",
      "        [-5.5848e-01,  5.7986e-02,  1.0366e+03],\n",
      "        [-5.0112e-01,  1.0288e-03,  9.9528e+02],\n",
      "        [-9.1168e-01, -3.0419e-01,  1.6047e+03],\n",
      "        [-7.2404e-01, -2.3016e-02,  1.2669e+03],\n",
      "        [-7.9906e-01, -1.2198e-01,  1.3610e+03],\n",
      "        [-5.5880e-01,  6.2397e-02,  1.0097e+03],\n",
      "        [-6.2278e-01, -3.6364e-03,  1.1154e+03],\n",
      "        [-4.3122e-01, -2.7308e-01,  9.1442e+02],\n",
      "        [-7.4325e-01, -4.2361e-02,  1.3008e+03],\n",
      "        [-5.7130e-01, -8.1028e-02,  9.3560e+02],\n",
      "        [-8.1302e-01, -1.4066e-01,  1.4318e+03],\n",
      "        [-4.6771e-01, -3.1771e-02,  9.7620e+02],\n",
      "        [-4.7512e-01, -4.6873e-02,  8.9625e+02],\n",
      "        [-6.1236e-01, -5.9291e-03,  1.0996e+03],\n",
      "        [-6.4651e-01, -2.7261e-02,  1.1385e+03],\n",
      "        [-9.1682e-01, -2.9767e-01,  1.6049e+03],\n",
      "        [-6.1378e-01,  6.6215e-04,  1.0985e+03],\n",
      "        [-7.1899e-01,  2.3016e-02,  1.2680e+03],\n",
      "        [-7.4940e-01, -4.1772e-02,  1.3128e+03],\n",
      "        [-9.0732e-01, -2.9966e-01,  1.5978e+03],\n",
      "        [-4.5927e-01, -1.0694e-01,  9.5491e+02],\n",
      "        [-6.8602e-01,  1.0195e-02,  1.2065e+03]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-7.7511e-01, -8.7367e-02,  1.3843e+03],\n",
      "        [-5.8736e-01,  7.9371e-02,  1.0839e+03],\n",
      "        [-6.3712e-01,  2.6309e-02,  1.1901e+03],\n",
      "        [-6.5810e-01,  4.5206e-02,  1.1964e+03],\n",
      "        [-7.4245e-01, -2.1763e-02,  1.3317e+03],\n",
      "        [-8.0632e-01, -1.2925e-01,  1.4311e+03],\n",
      "        [-4.5485e-01, -1.7350e-01,  9.8767e+02],\n",
      "        [-5.9931e-01,  5.2064e-02,  1.1182e+03],\n",
      "        [-6.0318e-01,  3.2811e-02,  1.0933e+03],\n",
      "        [-7.7723e-01, -8.3749e-02,  1.3897e+03],\n",
      "        [-7.3138e-01,  1.1462e-02,  1.2973e+03],\n",
      "        [-6.8503e-01, -2.1265e-02,  1.2620e+03],\n",
      "        [-7.0628e-01,  8.6669e-03,  1.1583e+03],\n",
      "        [-4.8223e-01,  2.3992e-02,  1.0214e+03],\n",
      "        [-8.6033e-01, -1.9551e-01,  1.4906e+03],\n",
      "        [-5.7216e-01,  1.0666e-01,  1.0594e+03],\n",
      "        [-5.8621e-01,  6.4571e-02,  1.0651e+03],\n",
      "        [-8.8353e-01, -2.6120e-01,  1.5745e+03],\n",
      "        [-6.2493e-01,  3.7319e-02,  1.1576e+03],\n",
      "        [-8.7634e-01, -2.6660e-01,  1.5733e+03],\n",
      "        [-6.5197e-01,  6.7081e-02,  1.1699e+03],\n",
      "        [-5.8159e-01, -7.5482e-03,  9.5427e+02],\n",
      "        [-8.7741e-01, -2.6918e-01,  1.5772e+03],\n",
      "        [-8.4340e-01, -2.0739e-01,  1.5070e+03],\n",
      "        [-8.9156e-01, -2.8155e-01,  1.5994e+03],\n",
      "        [-4.2555e-01, -4.9291e-01,  9.1895e+02],\n",
      "        [-4.4622e-01, -1.9314e-01,  9.7731e+02],\n",
      "        [-4.7295e-01, -2.6509e-01,  7.8955e+02],\n",
      "        [-8.5300e-01, -1.5460e-01,  1.4527e+03],\n",
      "        [-5.5383e-01, -4.0256e-02,  9.2665e+02],\n",
      "        [-8.7238e-01, -2.5140e-01,  1.5584e+03],\n",
      "        [-6.3048e-01,  6.1417e-02,  1.1632e+03]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-6.8190e-01,  3.3035e-02,  1.2079e+03],\n",
      "        [-8.7325e-01, -2.1987e-01,  1.5270e+03],\n",
      "        [-6.9130e-01,  7.3262e-02,  1.2457e+03],\n",
      "        [-8.7254e-01, -2.0693e-01,  1.5254e+03],\n",
      "        [-8.6288e-01, -1.5160e-01,  1.4621e+03],\n",
      "        [-8.6287e-01, -2.1386e-01,  1.5175e+03],\n",
      "        [-8.4641e-01, -1.9570e-01,  1.4930e+03],\n",
      "        [-8.4395e-01, -1.8262e-01,  1.4798e+03],\n",
      "        [-5.3926e-01, -5.7957e-02,  9.0779e+02],\n",
      "        [-5.6037e-01,  8.0665e-02,  1.0504e+03],\n",
      "        [-8.6954e-01, -2.2169e-01,  1.5279e+03],\n",
      "        [-5.8391e-01,  1.8285e-02,  9.7314e+02],\n",
      "        [-5.2561e-01,  7.6235e-02,  1.0287e+03],\n",
      "        [-8.2637e-01, -1.6388e-01,  1.4537e+03],\n",
      "        [-8.6845e-01, -2.0312e-01,  1.5126e+03],\n",
      "        [-5.1069e-01,  2.0673e-01,  9.7251e+02],\n",
      "        [-8.4113e-01, -1.5892e-01,  1.4497e+03],\n",
      "        [-8.7218e-01, -2.1988e-01,  1.5312e+03],\n",
      "        [-8.0301e-01, -1.1466e-01,  1.3715e+03],\n",
      "        [-4.1800e-01, -3.6913e-01,  7.5100e+02],\n",
      "        [-4.4170e-01, -2.0724e-01,  9.5940e+02],\n",
      "        [-7.3878e-01, -2.7964e-03,  1.2468e+03],\n",
      "        [-7.4688e-01, -7.6869e-02,  1.3298e+03],\n",
      "        [-4.6620e-01, -3.3813e-01,  9.8822e+02],\n",
      "        [-4.4517e-01, -1.2226e-01,  9.6729e+02],\n",
      "        [-5.9517e-01,  4.9534e-02,  9.9522e+02],\n",
      "        [-5.6899e-01, -4.4769e-03,  9.4968e+02],\n",
      "        [-8.6681e-01, -2.0079e-01,  1.5098e+03],\n",
      "        [-7.9294e-01, -1.0016e-01,  1.3843e+03],\n",
      "        [-8.7252e-01, -2.1293e-01,  1.5222e+03],\n",
      "        [-4.6547e-01, -4.8351e-04,  9.6632e+02],\n",
      "        [-4.7039e-01,  4.9925e-02,  9.2935e+02]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-6.3430e-01,  5.8214e-02,  1.1314e+03],\n",
      "        [-7.6164e-01, -7.8642e-02,  1.3550e+03],\n",
      "        [-4.4853e-01, -1.3110e-01,  9.7276e+02],\n",
      "        [-8.0579e-01, -1.8511e-01,  1.4328e+03],\n",
      "        [-7.0194e-01, -1.5411e-02,  1.1478e+03],\n",
      "        [-4.6855e-01, -4.2654e-01,  7.7505e+02],\n",
      "        [-7.3662e-01, -1.1342e-01,  1.3303e+03],\n",
      "        [-4.9092e-01, -5.1389e-01,  9.1906e+02],\n",
      "        [-8.3216e-01, -2.2217e-01,  1.4859e+03],\n",
      "        [-7.6572e-01, -8.6432e-02,  1.3618e+03],\n",
      "        [-4.3697e-01, -8.3866e-02,  9.5495e+02],\n",
      "        [-8.9151e-01, -2.5143e-01,  1.5089e+03],\n",
      "        [-9.0679e-01, -3.2360e-01,  1.5916e+03],\n",
      "        [-7.1818e-01, -3.2146e-02,  1.2439e+03],\n",
      "        [-5.2337e-01,  2.3404e-01,  1.0037e+03],\n",
      "        [-9.0198e-01, -3.2571e-01,  1.5919e+03],\n",
      "        [-9.0190e-01, -2.7450e-01,  1.5395e+03],\n",
      "        [-4.6007e-01,  1.1710e-02,  9.5552e+02],\n",
      "        [-7.6406e-01, -1.4911e-02,  1.2805e+03],\n",
      "        [-6.9935e-01, -2.0162e-02,  1.2432e+03],\n",
      "        [-8.0873e-01, -1.8093e-01,  1.4275e+03],\n",
      "        [-6.7010e-01, -4.1014e-02,  1.2066e+03],\n",
      "        [-4.5936e-01,  2.7253e-02,  9.6094e+02],\n",
      "        [-8.9459e-01, -3.2443e-01,  1.5866e+03],\n",
      "        [-6.8913e-01,  7.9761e-02,  1.2401e+03],\n",
      "        [-7.1628e-01, -4.2809e-02,  1.2447e+03],\n",
      "        [-5.7684e-01,  4.7618e-02,  1.0388e+03],\n",
      "        [-7.7165e-01, -6.7877e-02,  1.3031e+03],\n",
      "        [-5.2242e-01,  7.2953e-02,  1.0385e+03],\n",
      "        [-7.1699e-01,  1.7052e-02,  1.2132e+03],\n",
      "        [-7.5417e-01, -7.7660e-02,  1.3114e+03],\n",
      "        [-7.1197e-01,  6.5446e-04,  1.2956e+03]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-7.8192e-01, -1.3393e-01,  1.3634e+03],\n",
      "        [-9.2629e-01, -3.8425e-01,  1.6320e+03],\n",
      "        [-6.8776e-01, -5.8084e-02,  1.2342e+03],\n",
      "        [-5.9200e-01, -2.7577e-02,  1.0650e+03],\n",
      "        [-6.1030e-01, -2.7896e-02,  1.0113e+03],\n",
      "        [-5.9593e-01,  4.6120e-02,  1.0747e+03],\n",
      "        [-7.3214e-01, -7.9011e-02,  1.2772e+03],\n",
      "        [-9.3096e-01, -4.0916e-01,  1.6509e+03],\n",
      "        [-8.2971e-01, -2.1160e-01,  1.4107e+03],\n",
      "        [-4.6479e-01, -1.8160e-02,  9.7498e+02],\n",
      "        [-8.3562e-01, -2.3661e-01,  1.4758e+03],\n",
      "        [-4.6572e-01, -9.2138e-02,  9.8671e+02],\n",
      "        [-5.8240e-01,  3.3191e-02,  1.0631e+03],\n",
      "        [-7.5903e-01, -5.8006e-02,  1.3786e+03],\n",
      "        [-5.7668e-01,  9.9435e-02,  1.0947e+03],\n",
      "        [-6.3362e-01, -9.6347e-03,  1.1294e+03],\n",
      "        [-7.4414e-01, -6.5663e-02,  1.3154e+03],\n",
      "        [-8.3447e-01, -2.1843e-01,  1.4674e+03],\n",
      "        [-7.8315e-01, -1.3634e-01,  1.3638e+03],\n",
      "        [-6.4197e-01,  6.1475e-02,  1.1236e+03],\n",
      "        [-7.6826e-01, -4.1551e-02,  1.2757e+03],\n",
      "        [-4.7836e-01, -4.8450e-01,  7.7349e+02],\n",
      "        [-4.7252e-01,  3.0778e-02,  9.1656e+02],\n",
      "        [-5.0746e-01,  2.9290e-02,  9.8758e+02],\n",
      "        [-6.4519e-01,  5.4383e-03,  1.1907e+03],\n",
      "        [-9.3205e-01, -4.0631e-01,  1.6513e+03],\n",
      "        [-5.8441e-01,  3.9192e-02,  1.0531e+03],\n",
      "        [-6.4728e-01,  4.6482e-02,  1.1506e+03],\n",
      "        [-9.3668e-01, -4.1496e-01,  1.6577e+03],\n",
      "        [-7.6967e-01, -7.0175e-02,  1.3011e+03],\n",
      "        [-5.0687e-01,  5.8150e-02,  1.0369e+03],\n",
      "        [-8.7512e-01, -2.6834e-01,  1.4843e+03]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m model_instance\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      6\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader, \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m      8\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m      9\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\custom\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\custom\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\custom\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\custom\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[4], line 29\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     27\u001b[0m data_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_numbers[idx]\n\u001b[0;32m     28\u001b[0m matrix_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m matrix \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix_path\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Load matrix from a txt file\u001b[39;00m\n\u001b[0;32m     30\u001b[0m matrix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(matrix)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# 2D -> 3D tensor\u001b[39;00m\n\u001b[0;32m     31\u001b[0m matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(matrix)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\custom\\lib\\site-packages\\numpy\\lib\\npyio.py:1356\u001b[0m, in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1354\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1356\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1357\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1358\u001b[0m \u001b[43m            \u001b[49m\u001b[43munpack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munpack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1359\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\custom\\lib\\site-packages\\numpy\\lib\\npyio.py:999\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[0;32m    996\u001b[0m     data \u001b[38;5;241m=\u001b[39m _preprocess_comments(data, comments, encoding)\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read_dtype_via_object_chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 999\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_filelike\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1000\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1001\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimaginary_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimaginary_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiplines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilelike\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilelike\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbyte_converters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbyte_converters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1008\u001b[0m     \u001b[38;5;66;03m# This branch reads the file into chunks of object arrays and then\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m     \u001b[38;5;66;03m# casts them to the desired actual dtype.  This ensures correct\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;66;03m# string-length and datetime-unit discovery (like `arr.astype()`).\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;66;03m# Due to chunking, certain error reports are less clear, currently.\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filelike:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 100 #batch=32\n",
    "losses = [] \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_instance.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_instance(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    epoch_loss = running_loss / len(data_loader)  #epoch당 평균 loss 계산\n",
    "    losses.append(epoch_loss)  #add list\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss}')\n",
    "print('Finished Training')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# LOSS PLOT with log scale for y-axis\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs+1), losses, marker='o')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "#plt.yscale('log')  # y-axis를 로그 스케일로 설정\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "custom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
